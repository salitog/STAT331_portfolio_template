---
title: "STAT 331 Portfolio"
author: "Sal Gutierrez"
format: 
  html: 
    self-contained: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be an A.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from a Lab or Challenge assignment where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv` Challenge 4 - Data Importing

```{r wd-1-csv}
avocado <- read_csv(here("Labs", "Lab 4", "avocado.csv"))
prices <- read_csv("https://raw.githubusercontent.com/salitog/STATS331/main/HistoricalPrices.csv")
```

-   `xlsx` Practice Activity 4 - Data Importing

```{r wd-1-xlsx}
military <- read_xlsx(here::here("data", 
                                 "gov_spending_per_capita.xlsx"), 
                      sheet = "Share of Govt. spending"  , 
                      skip = 6, 
                      n_max = 186 )
```

-   `txt` Preview Activity 5.2 - Data Importing

```{r wd-1-txt}
message <- read_csv(here("data", "scrambled_message.txt"))
```

**WD-2: I can select necessary columns from a dataset:** Challenge 4 - Analysis

```{r wd-2}
avocado_size_mill <- millennials |>
  pivot_longer(cols = Small:XLarge,
               names_to = "AvocadoSize",
               values_to = "SizeSales") |>
 select(Date, Region, AveragePrice, `Total Volume`, Type:SizeSales)
```

**WD-3: I can filter rows from a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric: Lab 3 - Question 14

```{r wd-3-numeric}
hiphop_clean |>
  select(c("subj", "sex", "age", "ethnic_ctgr", "city", "bieber", "pop")) |>
  filter(ethnic_ctgr == "white",
           sex == "Male",
           age >= 17, 
           age <= 23,
           city >= 10000,
           city <= 60000) |>
  slice_max(order_by = bieber, n = 1) |>
  distinct(subj, .keep_all = TRUE)
```

-   character -- specifically a string: Lab 4 - Question 2

```{r wd-3-string}
# Dataframe for state related sales
state_sales <- avocado_clean |>
  filter(region %in% c("California", "SouthCarolina", "NewYork", "WestTexNewMexico"))

```

-   factor: Lab 3 - Question 12

```{r wd-3-factor}
hiphop_clean |>
  filter(ethnic_ctgr == "non-white", sex == "Female") |> # ethnic_ctgr and sex are factors
  group_by(word) |>
  summarize(mean_fam = mean(familiarity)) |>
  filter(mean_fam == min(mean_fam) |
           mean_fam == max(mean_fam)) |>
  arrange(desc(mean_fam))
```

-   date: Lab 5 - Question 2

```{r wd-3-date}
rodents <- surveys_summary |>
  mutate(day_of_week = weekdays(Date)) |> # Date is of Date type
  filter(taxa == "Rodent",
         !is.na(day_of_week)) |>
  group_by(day_of_week) |>
  summarize(count = n())
```

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric: Challenge 4 - Analysis

```{r wd-4-numeric}
avocado_diff <- millennials |>
  select(Date, Year, Region, Small, Large, `Sales%Change`) |>
  filter(Year == 2017) |>
  mutate(AvocadoSizeDiff = Large - Small, # Difference between Large and Small avocado sales
         AvocadoSizeDiff = scale(AvocadoSizeDiff), # Standardizing SalesDiff
         HousingSaleDiff = scale(`Sales%Change`))
```

-   character -- specifically a string: Lab 3 - Question 7

```{r wd-4-string}
hiphop_clean <- hiphop_clean |>
  mutate(ethnic_ctgr = if_else(ethnic == "white", "white", "non-white"))
```

-   factor: Lab 4 - Question 2

```{r wd-4-factor}
avocado_clean <- avocado |>
  mutate(type = as.factor(type),
         region = as.factor(region))
```

-   date: Lab 5 - Question 1

```{r wd-4-date}
surveys_summary <- surveys |>
  mutate(Date = ymd(paste(year, month, day, sep = "-")))
```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()`: Lab 4 - Question 5

```{r wd-5-left}
joined_top_metro <- top5_metro_sellers |>
  left_join(metro_region_sales, by = "region") |>
  select(region, `Total Volume`)
```

-   `right_join()`:

```{r wd-5-right}

```

-   `inner_join()`: Preview Activity 11 - Question 1

```{r wd-5-inner}
prof_info |>
  inner_join(prof_course)
```

-   `full_join()`: Preview Activity 11 - Question 2

```{r wd-5-full}
prof_info |>
  full_join(prof_course)
```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`:

```{r wd-6-semi}

```

-   `anti_join()`: Lab 4 - Question 2

```{r wd-6-anti}
# Dataframe for only metropolitan areas (cities)
metro_region_sales <- avocado_clean |>
  anti_join(total_us_sales) |> 
  anti_join(major_region_sales) |>
  anti_join(state_sales)
```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`: Challenge 4 - Analysis

```{r wd-7-long}
avocado_size_mill <- millennials |>
  pivot_longer(cols = Small:XLarge,
               names_to = "AvocadoSize",
               values_to = "SizeSales") |>
 select(Date, Region, AveragePrice, `Total Volume`, Type:SizeSales)
```

-   `pivot_wider()`: Lab 4 - Question 6

```{r wd-7-wide}
df_q6 <- california |>
  select(Date, AveragePrice, type, region) |> # select only necessary
  pivot_wider(names_from = type, # Get conventional and organic avg price on the same line
              values_from = AveragePrice) |>
  mutate(diff = abs(conventional - organic)) |> # Calculate the difference
  group_by(region) |> # group by region and not date
  summarize(`mean diff` = mean(diff)) # calculate mean of difference
```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

I've done this in the following provided assignments:

-   Example 1: Challenge 4

-   Example 2: Lab 5

**R-2: I can write well documented and tidy code.**

-   Example 1: Lab 4 - Question 6

```{r r-2-1}
df_q6 <- california |>
  select(Date, AveragePrice, type, region) |> # select only necessary
  pivot_wider(names_from = type, # Get conventional and organic avg price on the same line
              values_from = AveragePrice) |>
  mutate(diff = abs(conventional - organic)) |> # Calculate the difference
  group_by(region) |> # group by region and not date
  summarize(`mean diff` = mean(diff)) # calculate mean of difference
```

-   Example 2: Lab 3 - Question 3

```{r r-2-2}
hiphop |>
  group_by(word) |>
  summarize(num_subjects = n()) 

# n() gotten from https://www.rdocumentation.org/packages/dplyr/versions/0.7.8/topics/summarise
```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example 1: Challenge 4 - Data Importing

```{r r-3-1}
clean_housing <- function(dataset, gsub_expr) {
  dataset |>
    separate(col = `Mon-Yr`,
             into = c("Month", "Year"),
             sep = "-") |>
    select(Month, Year, 
           `Los Angeles`, 
           `San Diego`, 
           `San Francisco`, 
           `Sacramento`) |>
    rename("LosAngeles" = `Los Angeles`,
           "SanDiego" = `San Diego`, 
           "SanFrancisco" = `San Francisco`) |>
    filter(Year >= 15,
           Year <= 18) |>
    mutate(Year = as.factor(as.numeric(Year) + 2000),
           Month = as.factor(Month),
           across(`LosAngeles`:`Sacramento`, 
                  function(x) as.numeric(gsub(gsub_expr, "", x))))
}

housing_sales <- clean_housing(dataset = sales, 
                                gsub_expr = "%")

housing_prices <- clean_housing(dataset = prices,
                                gsub_expr = "[$,]")
```

-   Example 2: Lab 8 - Question 1

```{r r-3-2}
make_phrase <- function(day, item, verb, adjective, location) {
  
  plural_item <- pluralize_gift(item)
  num_word <- nums_to_string(day)
  
  ## Step 1: Replace NAs with blank strings
  verb <- verb |>
    str_replace_na("") |>
    str_replace("-", " ")
  adjective <- str_replace_na(adjective, "")
  location <- str_replace_na(location, "")
  
  ## Step 2: If the day is larger than 1, the items need pluralized! 
  item_name <- ifelse(day == 1, item, plural_item)
  
  ## Step 3: If the day is 1, you need to add an "a" or "an" before the gift 
  start <- ifelse(day == 1, "A", num_word)
  
  and <- ifelse(day == 2, "and", "")
  
  ## Step 4: Glue all of the pieces together to make a phrase! 
  sentence <- glue("{start} {adjective} {item_name} {verb} {location}{and}") |>
    str_replace_all("  ", " ")
  
  
  return(sentence)
}
```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   numeric variables: Challenge 4 - Analysis

```{r dvs-1-num}
ggplot(data = avocado_size_mill, 
       mapping = aes(x = HousesAvgPrice,
                     y = SizeSales,
                     color = Region)) +
  geom_point(alpha = 0.4) +
  facet_grid(~AvocadoSize) +
  labs(title = "House Average Price vs Avocado Sales (per size) by region",
       x = "Average Price for Single-Family Home (USD $)",
       y = "Avocados Sold") +
  theme(legend.position = "top")
```

-   numeric variables and categorical variables: Lab 4 - Question 5

```{r dvs-1-chr}
ggplot(data = joined_top_metro,
       mapping = aes(y = region,
                     x = `Total Volume`)) +
  geom_boxplot(mapping = aes(color = region)) +
  geom_jitter(mapping = aes(color = region, alpha = 0.2)) +
  labs(title = "Box Plots of top 5 avocado sellers by Metro Region",
       y = "Metro Region Name",
       x = "Average Number of Avocados Sold") +
  theme(legend.position = "none")
```

-   categorical variables: Lab 3 - Question 10

```{r dvs-1-fctr}
ggplot(data = demographics,
       mapping = aes(x = age,
                     y = ethnic,
                     color = ethnic,
                     fill = ethnic)) +
  geom_density_ridges(alpha = 0.5, 
                      scale = 0.3, 
                      jittered_points = TRUE, 
                      point_alpha=0.5,
                      point_shape=21) + 
  geom_point() +
  labs(title = "Distribution of Age amongst ethnic groups seperated by sex",
       x = "Age",
       y = "Ethnic Groups in Study") +
  facet_wrap(~sex) +
  theme(legend.position = "none")
```

-   dates: Challenge 4 - Analysis

```{r dvs-1-date}
ggplot(data = millennials, aes(x = Date, y = `Sales%Change`)) +
  geom_point(mapping = aes(color = Region)) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "% Change of Sales of Single-Family Home over time",
       x = "Year",
       y = "Percent Change in House Sales") +
  facet_wrap( ~Region ) +
  theme(legend.position = "none")
```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   Example 1: Challenge 4 - Analysis

```{r dvs-2-1}
# move my legend to the top
ggplot(data = avocado_size_mill, 
       mapping = aes(x = HousesAvgPrice,
                     y = SizeSales,
                     color = Region)) +
  geom_point(alpha = 0.4) +
  facet_grid(~AvocadoSize) +
  labs(title = "House Average Price vs Avocado Sales (per size) by region",
       x = "Average Price for Single-Family Home (USD $)",
       y = "Avocados Sold") +
  theme(legend.position = "top")
```

-   Example 2: Lab 5 - Question 1

```{r dvs-2-2}
# Used geom_text to remove the y axis and put annotations on the graph
ggplot(data = surveys, 
       mapping = aes(x = weight,
                     y = fct_reorder(species, weight, .fun = median))
       ) + 
  geom_jitter(alpha = .3,
              color = "darkseagreen") +
  geom_boxplot() +
  geom_text(aes(label = species), hjust = "right", x = 250, color = "black") +
  labs(title = "Distribution of Weight within each Species",
       x = "Weight (g)",
       y = "Species of Animal") + 
    theme(legend.position = "none", # removing legend
          axis.line.y = element_blank(),
          axis.text.y = element_blank(),
          axis.ticks.y = element_blank()) 
```

**DVS-3: I show creativity in my visualizations**

-   Example 1: Challenge 4 - Analysis

```{r dvs-3-1}
ggplot(data = avocado_diff, 
       mapping = aes(x = Date, 
                     y = Change, 
                     fill = Type)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~Region) +
  theme(legend.position = "top",
        axis.text.x = element_text(angle = 45)) +
  labs(title = "% Changes in Sales of Houses vs Sale Difference between 
       Large and Small avocados in 2017",
       y = "Magnitude of Sale Difference")
```

-   Example 2: Lab 9 - Question 5

```{r dvs-3-2}
allans <- stateNames |>
  filter(Name == c("Allan", "Alan", "Allen"),
         Sex == "M") |>
  group_by(Year, Name) |>
  summarize(num_names = sum(Count))

ggplot(data = allans,
       mapping = aes(x = Year,
                     y = num_names,
                     color = Name)) +
  geom_line() +
  labs(title = "Number of babies with the names Alan, Allan, or Allen, per year",
       y = "",
       x = "Year")
```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example 1: Challenge 3 - Plotting Data

```{r dvs-4-1}
hiphop_clean |>
  group_by(sex) |>
  mutate(across(intl:unclassifiable, mean)) |>
  summarize(max_mean = max(across(intl:unclassifiable, mean)))
```

-   Example 2:

```{r dvs-4-2}

```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1: Challenge 3 - Plotting Data

```{r dvs-5-1}
hiphop_clean |>
  group_by(sex) |>
  mutate(across(intl:unclassifiable, mean)) |>
  summarize(max_mean = max(across(intl:unclassifiable, mean)))
```

-   Example 2: Lab 4 - Question 7

```{r dvs-5-2}
q7_df <- california |>
  select(region, Small, Large, XLarge, type) |> # Selecting only necessary
  group_by(region, type) |>
  summarize(Small = mean(Small),
            Large = mean(Large),
            `Extra Large` = mean(XLarge)) |>
  pivot_longer(cols = Small:`Extra Large`,
               names_to = "size",
               values_to = "mean_sold")
```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   Example 1:

```{r dvs-6-1}

```

-   Example 2:

```{r dvs-6-2}

```

**DVS-7: I show creativity in my tables.**

-   Example 1: Challenge 9 - Filtering Multiple Values

```{r dvs-7-1}
allans2 |>
  left_join(totals) |>
  mutate(Allan = (Allan / Total) * 100,
         Allen = (Allen / Total) * 100,
         Alan = (Alan / Total) * 100) |>
  select(-Total) |>
  kable(align = c("c", "c", "c", "c")) |>
  kable_styling(font_size = 14) |>
  add_header_above(header = c("", "%", "%", "%"))
```

-   Example 2:

```{r dvs-7-2}

```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call \[included two examples of this :)\]

    -   Example 1: Challenge 4 - Data Cleaning

    ```{r pe-1-one-call1}
    # Created a function that cleans datasets
    clean_housing <- function(dataset, gsub_expr) {
      dataset |>
        separate(col = `Mon-Yr`,
                 into = c("Month", "Year"),
                 sep = "-") |>
        select(Month, Year, 
               `Los Angeles`, 
               `San Diego`, 
               `San Francisco`, 
               `Sacramento`) |>
        rename("LosAngeles" = `Los Angeles`,
               "SanDiego" = `San Diego`, 
               "SanFrancisco" = `San Francisco`) |>
        filter(Year >= 15,
               Year <= 18) |>
        mutate(Year = as.factor(as.numeric(Year) + 2000),
               Month = as.factor(Month),
               across(`LosAngeles`:`Sacramento`, 
                      function(x) as.numeric(gsub(gsub_expr, "", x))))
    }
    housing_sales <- clean_housing(dataset = sales, 
                                    gsub_expr = "%")
    housing_prices <- clean_housing(dataset = prices,
                                    gsub_expr = "[$,]")
    ```

    -   Example 2: Challenge 2 - Question 3 - Here, I used geom_text instead of having annotations

```{r pe-1-one-call2}
ggplot(data = surveys, 
       mapping = aes(y = species,
                     x = weight,
                     alpha = .2,
                     color = genus,
                     fill = genus),
       ) + 
  geom_density_ridges() +
  geom_text(aes(label = genus), nudge_y = 0.5, hjust = "right", x = 250, color = "white") +
  labs(title = "Distribution of Weight within each Species",
       x = "Weight (g)",
       y = "Species") +
  theme_dark() +
  theme(legend.position = "none" )
```

-   `across()`: Challenge 3 - Plotting Data

```{r pe-1-across}
hiphop_clean |>
  group_by(sex) |>
  mutate(across(intl:unclassifiable, mean)) |>
  summarize(max_mean = max(across(intl:unclassifiable, mean)))
```

-   `map()` functions: Lab 8 - Question 4

```{r pe-1-map-1}
s <- map(1:12, function(x) sing_line(xmas, line = x, phrase_col = Full.Phrase))
print(s)
```

**PE-2: I can write functions to reduce repetition in my code.**

-   Example 1: Challenge 4 - Housing Datasets

```{r pe2-1}
clean_housing <- function(dataset, gsub_expr) {
  dataset |>
    separate(col = `Mon-Yr`,
             into = c("Month", "Year"),
             sep = "-") |>
    select(Month, Year, 
           `Los Angeles`, 
           `San Diego`, 
           `San Francisco`, 
           `Sacramento`) |>
    rename("LosAngeles" = `Los Angeles`,
           "SanDiego" = `San Diego`, 
           "SanFrancisco" = `San Francisco`) |>
    filter(Year >= 15,
           Year <= 18) |>
    mutate(Year = as.factor(as.numeric(Year) + 2000),
           Month = as.factor(Month),
           across(`LosAngeles`:`Sacramento`, 
                  function(x) as.numeric(gsub(gsub_expr, "", x))))
}
```

-   Example 2: Lab 7 - Question 3.1

```{r pe2-2}
rescale_01 <- function(x) {
  if (! is.numeric(x)) {
    stop(paste("Vector is not numerical but of class type: ", class(x)))
  }
  if (length(x) < 1) {
    stop(paste("Vector's length must be at least 1. Got length ", length(x)))
  }
  # stopifnot(is.numeric(x), length(x) > 1)
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}

#calling the rescale_01 function
rescaled <- fish |> 
  mutate(length = rescale_01(length),
         weight = rescale_01(weight))
kable(head(rescaled, 8))
```

**PE-3:I can use iteration to reduce repetition in my code.**

-   `across()`: Challenge 3- Plotting Data

```{r pe-3-across}
hiphop_clean |>
  group_by(sex) |>
  mutate(across(intl:unclassifiable, mean)) |>
  summarize(max_mean = max(across(intl:unclassifiable, mean)))
```

-   `map()` functions (Provide 2 Examples): Lab 8 - Question 4

```{r pe-3-map-1}
s <- map(1:12, function(x) sing_line(xmas, line = x, phrase_col = Full.Phrase))
print(s)
```

```{r pe-3-map-2}

```

**PE-4: I can use modern tools when carrying out my analysis.**

-   Example 1:

```{r pe-4-1}

```

-   Example 2:

```{r pe-4-2}

```

## Data Simulation & Modeling

**DSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1:

```{r dsm-1-1}

```

-   Example 2:

```{r dsm-1-2}

```

**DSM-2: I can fit a linear regression and extract necessary summary measures.**

-   Example 1:

```{r dsm-2-1}

```

-   Example 2:

```{r dsm-2-2}

```

## Revising My Thinking

<!-- How did you revise your thinking throughout the course? How did you revise your thinking on the code examples you have provided in your portfolio? -->

So far, I\'ve received growing grades on some of my questions for labs and challenges. In almost every single assignment, I've made revisions to get an S on almost all G's I had. However, I have not stopped at just changing the code those questions with G's, but try to satisfy all suggestions or comments that the professor, or a classmate have left on my assignments even if I had an S grade. Every time I changed anything on my submitted code, I included a thoughtful reflection, explaining what I did, why I did it, and what I learned.

Further, I have been able to use what I\'ve learned from my reflections in other assignments. For example, for lab three I used the function mutate_at, which was already preceded by the across function. I then learned how to use the across function and used it in the rest of my coming labs and challenges.

## Extending My Thinking

<!-- How did you extended your thinking throughout the course? How did you extend your thinking on the code examples you have provided in your portfolio? -->

I have demonstrated that I extend my thinking by sometimes going above and beyond the specifications of the lab or assignment. For example, for challenge 2, I came up with a way to remove the repetition of annotations and boil everything down to a single line using the geom_text function. Another example is on lab 3 where I used density ridges to explore my data. However, I figured out how to jitter my data points within the ridges so that the plot was more interesting looking.

So far, the assignment I've enjoyed the most is Challenge 4, the analysis of avocados and milenials. The liberty to use the data you want, and then decide what plots and transformations you need to do is awesome. I think I did a good job to make this assignment very analytic and thoughtful.

## Peer Support & Collaboration

<!-- Include an image of feedback you gave that you are proud of (either in a peer review or in Discord) -->

Peer review is very important to me as that is the main way I can make improvements to my code. I try to complete my peer reviews as soon as I possibly can. I try to refer to the style guide as much as possible. Sometimes, I find that other people do the same mistakes I have done before so I try to help with constructive feedback and a solution to their issues. I am always trying to look thoroughly through my peers\' code and try to identify the areas where they can improve.

As for when I am working with my Lab group, I\'ve tried to give them the opportunity to take the writer role so that the members who are not normally coding a lot, can practice their coding. I try to make sure to give my group mates time to think over the problems instead of taking over the conversation and solution ideation. Even though I am a computer science major and code every day, I take a step back and let my group mates come up with different ideas to improve our code without me taking control of the keyboard or discussion. There has been many times where they\'ve come up with code that I would\'ve never thought of. Having this diverse set of skills in my group is specially important because everybody brings different perspectives and ideas to the table.

I am sadly missing in this area where I could be helping people on discord. However, because of my work load, I catch myself working on labs and assignments close to the due date, and by the time people have already answered most questions. But, I will try to work on this and be more participating on the Discord Server.
